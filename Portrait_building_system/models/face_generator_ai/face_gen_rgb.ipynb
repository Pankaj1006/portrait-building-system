{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_gen_rgb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX3Bu4ufX0Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install imageio\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJwkqWTWX50N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZXCNlQWYDOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import UpSampling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gll_MoOWYGW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "default_image_size=tuple((64, 64))\n",
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        image = cv2.cvtColor(image, cv2.cv2.COLOR_BGR2RGB)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)  \n",
        "            \n",
        "            return  img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZiPPLXoed9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o1BzWdNeeA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory_root_leye='/content/drive/My Drive/extract/output/left_eye'\n",
        "image_list=[]\n",
        "img_name=[]\n",
        "list_img_filename=[]\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr2YqBDReeDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for  dirname,dis,filenames in os.walk(directory_root_leye):\n",
        "    #list_img_array.append(dirname)\n",
        "    for filename in filenames:\n",
        "     \n",
        "        if filename.endswith(\".jpg\") == True or filename.endswith(\".JPG\") == True:\n",
        "            image_list.append(convert_image_to_array(os.path.join(dirname,filename)))\n",
        "            img_name.append(dirname)\n",
        "            list_img_filename.append(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gxh4bTmeeGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_img_filename=np.array(list_img_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_svhwMZeeLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory_root_reye='/content/drive/My Drive/extract/output/right_eye'\n",
        "image_list_re=[]\n",
        "for  dirname,dis,filenames in os.walk(directory_root_reye):\n",
        "    #list_img_array.append(dirname)\n",
        "    for filename in filenames[0:1500]:\n",
        "     \n",
        "        if filename.endswith(\".jpg\") == True or filename.endswith(\".JPG\") == True:\n",
        "            image_list_re.append(convert_image_to_array(os.path.join(dirname,filename)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM0HNpVmeeN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "directory_root_reye='/content/drive/My Drive/extract/output/nose'\n",
        "image_list_no=[]\n",
        "for  dirname,dis,filenames in os.walk(directory_root_reye):\n",
        "    #list_img_array.append(dirname)\n",
        "    for filename in filenames[0:1500]:\n",
        "     \n",
        "        if filename.endswith(\".jpg\") == True or filename.endswith(\".JPG\") == True:\n",
        "            image_list_no.append(convert_image_to_array(os.path.join(dirname,filename)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkgfxJMleeRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " directory_root_reye='/content/drive/My Drive/extract/output/lip'\n",
        "image_list_lip=[]\n",
        "for  dirname,dis,filenames in os.walk(directory_root_reye):\n",
        "    #list_img_array.append(dirname)\n",
        "    for filename in filenames[0:1500]:\n",
        "     \n",
        "        if filename.endswith(\".jpg\") == True or filename.endswith(\".JPG\") == True:\n",
        "            image_list_lip.append(convert_image_to_array(os.path.join(dirname,filename)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFCRUbYBeeTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory_root_reye='/content/drive/My Drive/extract/output/left_eyebrow'\n",
        "image_list_ly=[]\n",
        "for  dirname,dis,filenames in os.walk(directory_root_reye):\n",
        "    #list_img_array.append(dirname)\n",
        "    for filename in filenames[0:1500]:\n",
        "     \n",
        "        if filename.endswith(\".jpg\") == True or filename.endswith(\".JPG\") == True:\n",
        "            image_list_ly.append(convert_image_to_array(os.path.join(dirname,filename)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7i3VLPzeeWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory_root_reye='/content/drive/My Drive/extract/output/right_eyebrow'\n",
        "image_list_ry=[]\n",
        "for  dirname,dis,filenames in os.walk(directory_root_reye):\n",
        "    #list_img_array.append(dirname)\n",
        "    for filename in filenames[0:1500]:\n",
        "     \n",
        "        if filename.endswith(\".jpg\") == True or filename.endswith(\".JPG\") == True:\n",
        "            image_list_ry.append(convert_image_to_array(os.path.join(dirname,filename)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWg_qdbxeeZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory_root_reye='/content/drive/My Drive/extract/output/chin'\n",
        "Y_train=[]\n",
        "for  dirname,dis,filenames in os.walk(directory_root_reye):\n",
        "    #list_img_array.append(dirname)\n",
        "    for filename in filenames:\n",
        "     \n",
        "        if filename.endswith(\".jpg\") == True or filename.endswith(\".JPG\") == True:\n",
        "            Y_train.append(convert_image_to_array(os.path.join(dirname,filename)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDIs1ZO3eeb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_list=np.array(image_list)\n",
        "image_list_re=np.array(image_list_re)\n",
        "image_list_no=np.array(image_list_no)\n",
        "image_list_lip=np.array(image_list_lip)\n",
        "image_list_ry=np.array(image_list_ry)\n",
        "image_list_ly=np.array(image_list_ly)\n",
        "Y_train=np.array(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbHt0SIjeeec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(Y_train[0] ,cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8sebzuveeh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_1=image_list/255\n",
        "x_2=image_list_re/255\n",
        "x_3=image_list_no/255\n",
        "x_4=image_list_lip/255\n",
        "x_5=image_list_ry/255\n",
        "x_6=image_list_ly/255\n",
        "y=Y_train/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug5cF2tkeeJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "added_noise = np.random.randn(*(64,64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRAFi7iHed8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise_factor = 0.2\n",
        "sample_image = y[101]\n",
        "noisy_sample_image = sample_image + noise_factor * np.random.randn(*(64,64,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YJLtQHTed5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow((tf.squeeze(noisy_sample_image)) ,cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA3s4EetfOID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_N = []\n",
        "noise_factor = 0.2\n",
        "\n",
        "for sample_image in y:\n",
        "  sample_image_noisy = sample_image + noise_factor * np.random.randn(*(64,64,1))\n",
        "  sample_image_noisy = np.clip(sample_image_noisy, 0., 1.)\n",
        "  X_N.append(sample_image_noisy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTvsmVIqfON-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_N=np.array(X_N)\n",
        "XX_N=X_N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h38ghIZFfOQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow((tf.squeeze(XX_N[0])),cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXIi3VmZfOUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left_eye_input=Input(shape=(64,64,3))\n",
        "right_eye_input=Input(shape=(64,64,3))\n",
        "left_eyebrow_input=Input(shape=(64,64,3))\n",
        "right_eyebrow_input=Input(shape=(64,64,3))\n",
        "nose_input=Input(shape=(64,64,3))\n",
        "lip_input=Input(shape=(64,64,3))\n",
        "X_le= left_eye_input\n",
        "X_le=layers.Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='same', use_bias=False)(X_le)\n",
        "X_re= right_eye_input\n",
        "X_re=layers.Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='same', use_bias=False)(X_re)\n",
        "x_l= left_eyebrow_input\n",
        "x_l=layers.Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='same', use_bias=False)(x_l)\n",
        "x_r= right_eyebrow_input\n",
        "x_r=layers.Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='same', use_bias=False)(x_r)\n",
        "x_n= nose_input\n",
        "x_n=layers.Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='same', use_bias=False)(x_n)\n",
        "x_li= lip_input\n",
        "x_li=layers.Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='same', use_bias=False)(x_li)\n",
        "\n",
        "from keras.layers import Concatenate\n",
        "\n",
        "X1 = Concatenate()([X_le,X_re])\n",
        "X1=layers.Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same', use_bias=False)(X1) \n",
        "X1=layers.BatchNormalization()(X1)\n",
        "X1=layers.LeakyReLU()(X1)\n",
        "\n",
        "\n",
        "X2 = Concatenate()([x_l,x_r])\n",
        "X2=layers.Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same', use_bias=False)(X1) \n",
        "X2=layers.BatchNormalization()(X1)\n",
        "X2=layers.LeakyReLU()(X1)\n",
        "\n",
        "\n",
        "\n",
        "X3 = Concatenate()([x_n,x_li])\n",
        "X3=layers.Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same', use_bias=False)(X3) \n",
        "X3=layers.BatchNormalization()(X3)\n",
        "X3=layers.LeakyReLU()(X3)\n",
        "\n",
        "#X=layers.Reshape((16, 16, 256))(X)\n",
        "X = Concatenate()([X1,X2,X3])\n",
        "    # Because we used \"same\" padding and stride = 1, the output is the same size as input 7 x 7 but with 128 filters instead\n",
        "    # Resulting in 8 x 8x 128\n",
        "X=layers.Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same', use_bias=False)(X) \n",
        "X=layers.BatchNormalization()(X)\n",
        "X=layers.LeakyReLU()(X)\n",
        "\n",
        "    # Because we used \"same\" padding and stride = 2, the output is double the size of the input 14 x 14 but with 64 filters instead\n",
        "    # Resulting in 14 x 14 x 64\n",
        "X=layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(X)\n",
        "X=layers.BatchNormalization()(X)\n",
        "X=layers.LeakyReLU()(X)\n",
        "\n",
        "    # Because we used \"same\" padding and stride = 2, the output is double the size of the input 28 x 28 but with 1 filter instead\n",
        "    # Resulting in 28 x 28 x 1\n",
        "X=layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(X)\n",
        "#X= layers.Conv2D(64, (3, 3), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "X=layers.BatchNormalization()(X)\n",
        "X=layers.LeakyReLU()(X)\n",
        "\n",
        "X= Conv2D(64, (2, 2), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "X=layers.BatchNormalization()(X)\n",
        "X=MaxPooling2D((2, 2), padding='same')(X)\n",
        "#X=layers.Conv2DTranspose(9, (5, 5), strides=(2, 2), padding='same', use_bias=False)(X) \n",
        "#X= Conv2D(32, (1, 1), strides = (1, 1))(X)\n",
        "#X=layers.BatchNormalization()(X)\n",
        "#X=layers.LeakyReLU()(X)\n",
        "X= Conv2D(3, (3, 3), strides=(1, 1), padding='same', use_bias=False,activation='tanh')(X) \n",
        "generator= Model([left_eye_input,right_eye_input,left_eyebrow_input,right_eyebrow_input,nose_input,lip_input],X)\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuRqKLX_fOLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_discriminator_model():\n",
        "    data=Input(shape=(32,32,3))\n",
        "    x=layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(data)\n",
        "    x=layers.LeakyReLU()(x)\n",
        "    x=layers.Dropout(0.3)(x)\n",
        "\n",
        "    x=layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
        "    x=layers.LeakyReLU()(x)\n",
        "    x=layers.Dropout(0.3)(x)\n",
        "\n",
        "    x=layers.Flatten()(x)\n",
        "    x=layers.Dense(3072)(x)\n",
        "    model=Model(data,x)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2iBfCO0fOGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def genra():\n",
        "  data=Input(shape=(64,64,3))\n",
        "  \n",
        "  # Let's build the encoder CNN\n",
        "  x=Conv2D(18, (3,3), strides=1,padding=\"same\", input_shape=(32, 32, 3))(data)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=layers.Activation('relu')(x)\n",
        "  x=layers.AveragePooling2D((2,2), padding=\"same\")(x)\n",
        "\n",
        "  x=layers.Conv2D(32, (3,3), strides=1, padding=\"same\")(x)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=layers.Activation('relu')(x)\n",
        "  x=layers.AveragePooling2D((2,2), padding=\"same\")(x)\n",
        "\n",
        "  x=layers.Conv2D(16, (3,3), strides=1, padding=\"same\")(x)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=layers.Activation('relu')(x)\n",
        "  x=layers.AveragePooling2D((2,2), padding=\"same\")(x) # Encoded image (Code Layer)\n",
        "\n",
        "\n",
        "# Let's build the decoder CNN \n",
        "  x=layers.Conv2D(16, (3,3), strides=1, padding=\"same\")(x)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=layers.Activation('relu')(x)\n",
        "  x=layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "  x=layers.Conv2D(32, (3,3), strides=1, padding=\"same\")(x)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=layers.Activation('relu')(x)\n",
        "  x=layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "\n",
        "  x=layers.Conv2D(64, (3,3), strides=1, padding=\"same\")(x)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=layers.Activation('relu')(x)\n",
        "  x=layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "  x=layers.Conv2D(3, (3,3), strides=1, activation='sigmoid', padding=\"same\")(x)\n",
        "  model=Model(data,x)\n",
        "  return  model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_etzpmMfOCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = make_discriminator_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOOaPhuxfgXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator2=genra()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogk_m1QHfgd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bnjrgOnfgg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator2.compile(optimizer=keras.optimizers.Adam(lr=0.01),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hClZZBflfgmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XX_N.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FrEcUZLfgqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator2.fit(XX_N,y,epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpFel6nifgvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c=discriminator2.predict(y[0:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFRoGwvzfgyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow((tf.squeeze(c[0])),cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzCI47qUfg3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, generator, discriminator1, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.generator =  generator\n",
        "        self.discriminator2 = discriminator2\n",
        "\n",
        "    def train_step(self, data):\n",
        "        [x_1,x_2,x_3,x_4,x_5,x_6],y=data\n",
        "        #if isinstance(data, tuple):\n",
        "            #[x_1,x_2,x_3,x_4,x_5,x_6],y= data[0]\n",
        "\n",
        "        with tf.GradientTape() as tape,tf.GradientTape() as dic_tape:\n",
        "            z = generator([x_1,x_2,x_3,x_4,x_5,x_6])\n",
        "            y_real = discriminator2(y)\n",
        "            y_fack= discriminator2(z)\n",
        "            \n",
        "            fack_image_loss =tf.reduce_mean(keras.losses.binary_crossentropy(y,y_fack))\n",
        "            true_image_loss =tf.reduce_mean(keras.losses.binary_crossentropy(y_real,z))\n",
        "\n",
        "            \n",
        "        grads = tape.gradient(fack_image_loss, self.discriminator2.trainable_weights)\n",
        "        grads2 = dic_tape.gradient(true_image_loss, self.generator.trainable_weights)\n",
        "        \n",
        "        self.optimizer.apply_gradients(zip(grads, self.discriminator2.trainable_weights))\n",
        "        self.optimizer.apply_gradients(zip(grads2, self.generator.trainable_weights))\n",
        "        \n",
        "        \n",
        "          \n",
        "        \n",
        "        \n",
        "          \n",
        "\n",
        "        return {\n",
        "            \"fack_loss\": fack_image_loss,\n",
        "            \"true_loss\": true_image_loss,\n",
        "        }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27cRuN_Ofg9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae1 = VAE(generator, discriminator2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4EnMuXefhCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "vae1.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0003))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEjqsdZ3fhEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow((tf.squeeze(x_0[0])),cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ8r3N8_fg65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae1.fit([x_1,x_2,x_3,x_4,x_5,x_6],y, epochs=15, batch_size=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCprD-rAfg1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "t=generator.predict(([x_1[0:1],x_2[0:1],x_3[0:1],x_4[0:1],x_5[0:1],x_6[0:1]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPvRP2azfgtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(t[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B5m9q6Vfgj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1=discriminator2.predict(t[0:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPOAZjPDfgbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_plot = plt.imshow(t1[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "786y3401hBd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t2=discriminator2.predict(t1[0:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIxdL40zhF_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_plot = plt.imshow(t2[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kB7wA-2hGEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.shape\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68KHZ3ZThGK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator.save('my_gen_rgb.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KaGLJ1jhGVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator2.save('my_gen_rgb.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNH_ErjqhGI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p-x2Yx7hGC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}